# ── Model Configuration ───────────────────────────────────────────────────────
model:
  # Base model to use (Student and initial Teacher)
  name: "Qwen/Qwen3-4B-Thinking-2507"
  attn_implementation: "flash_attention_2"

# ── Dataset Configuration ─────────────────────────────────────────────────────
datasets:
  - name: "lightonai/olmo_think_fr_sdft"
    split: "train[:10%]"
    # Map dataset columns to 'query' and 'demonstration'
    column_map:
      query: "query"
      demonstration: "demonstration_no_think"

validation:
  split_ratio: 0.01               # 1% for validation
  seed: 42

# ── SDFT Algorithm Parameters ─────────────────────────────────────────────────
sdft:
  ema_alpha: 0.01 # Exponential Moving Average decay for the teacher model

  # Generation settings for the student (vLLM)
  max_gen_length: 1024
  generation_temperature: 1.0
  generation_top_p: null
  generation_top_k: null
  mask_first_n_tokens: 0 # Mask the first N tokens from the loss 
  vllm_sync_interval: 1 # How often to sync Student weights to vLLM engine (in steps)

  # Template used to prime the teacher model (French)
  teacher_prompt_template: |
    {query}

    This is an example for a response to the question:
    {demonstration}

    Now answer with a response of your own, including the thinking process. You must reason in French inside <think></think>.

# ── vLLM Engine Configuration ─────────────────────────────────────────────────
vllm:
  gpu_memory_utilization: 0.35 # How much GPU memory vLLM reserves.
  # tensor_parallel_size: 1
  data_parallel_size: 2
  enable_sleep_mode: true         # Required for the code's memory sharing logic
  enforce_eager: false
  max_model_len: 2048

# ── Training Arguments (HuggingFace) ──────────────────────────────────────────
training:
  output_dir: "/opt/home/maxence/EasyTraining/training_results/sdft_test"
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 32
  learning_rate: 1.0e-5
  lr_scheduler_type: "cosine"
  warmup_steps: 60
  num_train_epochs: 2
  optim: "adamw_torch"
  bf16: true                      # Using bf16 for Qwen models
  fp16: false
  logging_steps: 1
  save_strategy: "epoch"
  eval_strategy: "steps"
  eval_steps: 50
  report_to: "wandb"
  max_grad_norm: 1.0
  gradient_checkpointing: true

# ── LoRA / PEFT Configuration ─────────────────────────────────────────────────
lora:
  enabled: false
  r: 32
  alpha: 64
  dropout: 0.05
  bias: "none"
  target_modules: 
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"

# ── Logging & Callbacks ───────────────────────────────────────────────────────
wandb:
  enabled: true
  project: "EasyTraining"
  run_name: "sdft_test"

eval_samples:
  enabled: true
  num_samples: 3
  max_new_tokens: 256